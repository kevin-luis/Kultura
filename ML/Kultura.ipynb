{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cMmAuMTm8aUN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7yTFAIxAFi",
        "outputId": "5cee292b-f35b-469b-c554-1987762b27a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cV8IE33BirOF0w35ysfHwrqtIssXlw19\n",
            "To: /content/extracted_data/data.zip\n",
            "100%|██████████| 1.07G/1.07G [00:11<00:00, 90.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/extracted_data: ['mask_dataset', 'data.zip']\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "# Set the file ID and download URL\n",
        "file_id = '1cV8IE33BirOF0w35ysfHwrqtIssXlw19'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Specify the local directory for extraction\n",
        "output_dir = '/content/extracted_data'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(url, output_dir + '/data.zip', quiet=False)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(output_dir + '/data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "# Print the list of extracted files\n",
        "extracted_files = os.listdir(output_dir)\n",
        "print(f\"Files extracted to {output_dir}: {extracted_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WXEl6a_44PG1"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/content/extracted_data/'\n",
        "train_dir = os.path.join(BASE_DIR, 'mask_dataset/training_set')\n",
        "validation_dir = os.path.join(BASE_DIR, 'mask_dataset/test_set')\n",
        "# class_labels = os.listdir(train_dir)\n",
        "# print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Content of base directory:\")\n",
        "print(os.listdir(f'{BASE_DIR}/mask_dataset'))\n",
        "\n",
        "print(\"\\nContent of bujuh test set:\")\n",
        "print(os.listdir(f'{validation_dir}/bujuh'))\n",
        "print(len(os.listdir(f'{validation_dir}/bujuh')))\n",
        "\n",
        "print(\"\\nContent of bujuh training set:\")\n",
        "print(os.listdir(f'{train_dir}/bujuh'))\n",
        "print(len(os.listdir(f'{train_dir}/bujuh')))\n",
        "\n",
        "print(\"\\nContent of dalem test set:\")\n",
        "print(os.listdir(f'{validation_dir}/dalem'))\n",
        "print(len(os.listdir(f'{validation_dir}/dalem')))\n",
        "\n",
        "print(\"\\nContent of dalem training set:\")\n",
        "print(os.listdir(f'{train_dir}/dalem'))\n",
        "print(len(os.listdir(f'{train_dir}/dalem')))\n",
        "\n",
        "print(\"\\nContent of dalem test set:\")\n",
        "print(os.listdir(f'{validation_dir}/dalem'))\n",
        "print(len(os.listdir(f'{validation_dir}/dalem')))\n",
        "\n",
        "print(\"\\nContent of keras training set:\")\n",
        "print(os.listdir(f'{train_dir}/keras'))\n",
        "print(len(os.listdir(f'{train_dir}/keras')))\n",
        "\n",
        "print(\"\\nContent of penasar test set:\")\n",
        "print(os.listdir(f'{validation_dir}/penasar'))\n",
        "print(len(os.listdir(f'{validation_dir}/penasar')))\n",
        "\n",
        "print(\"\\nContent of penasar training set:\")\n",
        "print(os.listdir(f'{train_dir}/penasar'))\n",
        "print(len(os.listdir(f'{train_dir}/penasar')))\n",
        "\n",
        "print(\"\\nContent of sidakarya test set:\")\n",
        "print(os.listdir(f'{validation_dir}/sidakarya'))\n",
        "print(len(os.listdir(f'{validation_dir}/sidakarya')))\n",
        "\n",
        "print(\"\\nContent of sidakarya training set:\")\n",
        "print(os.listdir(f'{train_dir}/sidakarya'))\n",
        "print(len(os.listdir(f'{train_dir}/sidakarya')))\n",
        "\n",
        "print(\"\\nContent of tua test set:\")\n",
        "print(os.listdir(f'{validation_dir}/tua'))\n",
        "print(len(os.listdir(f'{validation_dir}/tua')))\n",
        "\n",
        "print(\"\\nContent of tua training set:\")\n",
        "print(os.listdir(f'{train_dir}/tua'))\n",
        "print(len(os.listdir(f'{train_dir}/tua')))\n",
        "\n",
        "print(\"\\nContent of wijil set:\")\n",
        "print(os.listdir(f'{validation_dir}/wijil'))\n",
        "print(len(os.listdir(f'{validation_dir}/wijil')))\n",
        "\n",
        "print(\"\\nContent of wijil training set:\")\n",
        "print(os.listdir(f'{train_dir}/wijil'))\n",
        "print(len(os.listdir(f'{train_dir}/wijil')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj3geWekv2MN",
        "outputId": "3052cd5a-8c0c-470a-e36a-465e0f8170a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of base directory:\n",
            "['test_set', 'training_set']\n",
            "\n",
            "Content of bujuh test set:\n",
            "['345.jpg', '326.jpg', '325.jpg', '317.jpg', '348.jpg', '313.jpg', '339.jpg', '332.jpg', '330.jpg', '319.JPG']\n",
            "10\n",
            "\n",
            "Content of bujuh training set:\n",
            "['301.jpg', '309.jpg', '320.jpg', '346.jpg', '322.JPG', '342.jpg', '308.JPG', '314.jpg', '310.jpg', '304.jpg', '347.jpg', '349.jpg', '312.jpg', '321.jpg', '331.jpg', '300.JPG', '329.JPG', '307.JPG', '338.jpg', '324.jpg', '336.jpg', '337.jpg', '316.jpg', '335.jpg', '334.jpg', '323.jpg', '343.jpg', '303.jpg', '306.jpg', '305.jpg', '344.jpg', '341.jpg', '311.jpg', '333.jpg', '340.jpg', '327.jpg', '328.jpg', '302.jpg', '318.JPG', '315.jpg']\n",
            "40\n",
            "\n",
            "Content of dalem test set:\n",
            "['89.jpg', '80.jpg', '76.jpg', '63.JPG', '69.jpg', '82.jpg', '95.jpg', '98.jpg', '75.jpg', '67.JPG']\n",
            "10\n",
            "\n",
            "Content of dalem training set:\n",
            "['84.jpg', '94.jpg', '50.jpg', '73.jpg', '88.jpg', '92.jpg', '90.jpg', '68.JPG', '99.jpg', '51.JPG', '77.JPG', '87.jpg', '59.JPG', '79.jpg', '72.jpg', '96.jpg', '78.jpg', '70.jpg', '54.jpg', '74.jpg', '97.jpg', '55.JPG', '66.jpg', '62.JPG', '60.JPG', '91.jpg', '71.jpg', '58.jpg', '53.JPG', '85.JPG', '57.JPG', '52.jpg', '64.JPG', '86.jpg', '65.jpg', '81.jpg', '61.jpg', '56.jpg', '93.JPG', '83.jpg']\n",
            "40\n",
            "\n",
            "Content of dalem test set:\n",
            "['89.jpg', '80.jpg', '76.jpg', '63.JPG', '69.jpg', '82.jpg', '95.jpg', '98.jpg', '75.jpg', '67.JPG']\n",
            "10\n",
            "\n",
            "Content of keras training set:\n",
            "['101.jpg', '147.jpg', '131.jpg', '124.JPG', '121.JPG', '110.jpg', '118.jpg', '143.jpg', '129.JPG', '116.JPG', '105.JPG', '146.JPG', '127.JPG', '111.jpg', '149.jpg', '137.JPG', '123.jpg', '103.JPG', '106.jpg', '114.JPG', '136.jpg', '122.jpg', '128.jpg', '134.jpg', '109.JPG', '133.JPG', '107.JPG', '140.JPG', '108.jpg', '141.jpg', '138.JPG', '102.jpg', '142.jpg', '112.JPG', '135.JPG', '100.JPG', '115.jpg', '104.jpg', '120.jpg', '144.jpg']\n",
            "40\n",
            "\n",
            "Content of penasar test set:\n",
            "['226.jpg', '245.jpg', '217.jpg', '239.jpg', '232.JPG', '213.jpg', '225.jpg', '248.jpg', '219.jpg', '230.jpg']\n",
            "10\n",
            "\n",
            "Content of penasar training set:\n",
            "['237.jpg', '224.jpg', '221.jpg', '226.jpg', '234.jpg', '203.jpg', '206.jpg', '205.jpg', '247.jpg', '249.jpg', '245.jpg', '236.jpg', '218.jpg', '201.jpg', '216.jpg', '209.jpg', '241.jpg', '233.jpg', '228.jpg', '215.jpg', '208.jpg', '239.jpg', '246.jpg', '240.jpg', '202.jpg', '235.jpg', '220.jpg', '227.jpg', '242.jpg', '212.jpg', '225.jpg', '223.JPG', '229.jpg', '231.jpg', '244.jpg', '204.jpg', '210.jpg', '248.jpg', '243.jpg', '214.jpg', '211.jpg', '219.jpg', '238.jpg', '200.JPG', '207.jpg', '222.jpg']\n",
            "46\n",
            "\n",
            "Content of sidakarya test set:\n",
            "['44.JPG', '5.JPG', '8.JPG', '31.JPG', '32.JPG', '38.JPG', '36.JPG', '24.JPG', '26.JPG', '20.JPG']\n",
            "10\n",
            "\n",
            "Content of sidakarya training set:\n",
            "['13.jpg', '10.jpg', '41.JPG', '1.JPG', '39.JPG', '43.jpg', '49.JPG', '45.jpg', '7.JPG', '16.JPG', '21.JPG', '22.JPG', '4.JPG', '9.jpg', '11.JPG', '40.JPG', '33.JPG', '17.JPG', '35.JPG', '3.jpg', '27.JPG', '47.JPG', '29.JPG', '28.JPG', '30.JPG', '0.jpg', '19.JPG', '25.JPG', '46.JPG', '18.JPG', '34.JPG', '14.jpg', '23.JPG', '2.jpg', '15.JPG', '42.JPG', '37.JPG', '12.jpg', '6.JPG', '48.JPG']\n",
            "40\n",
            "\n",
            "Content of tua test set:\n",
            "['198.jpg', '163.JPG', '189.jpg', '176.jpg', '175.jpg', '195.JPG', '180.JPG', '169.JPG', '167.JPG', '182.jpg']\n",
            "10\n",
            "\n",
            "Content of tua training set:\n",
            "['164.JPG', '184.jpg', '192.JPG', '160.jpg', '156.jpg', '168.JPG', '183.jpg', '166.JPG', '155.jpg', '190.jpg', '178.JPG', '199.jpg', '172.jpg', '186.jpg', '151.JPG', '174.jpg', '179.JPG', '187.jpg', '170.JPG', '193.JPG', '157.jpg', '153.jpg', '158.jpg', '150.JPG', '197.jpg', '194.JPG', '162.jpg', '177.JPG', '181.jpg', '154.jpg', '159.jpg', '152.jpg', '188.jpg', '196.jpg', '191.jpg', '173.jpg', '171.jpg', '185.jpg', '161.jpg', '165.JPG']\n",
            "40\n",
            "\n",
            "Content of wijil set:\n",
            "['289.jpg', '263.jpg', '267.jpg', '269.jpg', '275.jpg', '282.jpg', '295.jpg', '280.jpg', '298.jpg', '276.jpg']\n",
            "10\n",
            "\n",
            "Content of wijil training set:\n",
            "['284.jpg', '266.jpg', '258.jpg', '293.jpg', '296.jpg', '271.jpg', '278.JPG', '279.JPG', '297.jpg', '250.JPG', '290.JPG', '255.JPG', '281.jpg', '265.jpg', '260.jpg', '268.jpg', '264.jpg', '299.jpg', '273.jpg', '294.jpg', '259.jpg', '288.jpg', '261.jpg', '272.jpg', '253.JPG', '251.JPG', '274.jpg', '292.jpg', '283.jpg', '254.JPG', '256.jpg', '286.jpg', '262.jpg', '285.jpg', '270.jpg', '252.JPG', '291.jpg', '277.JPG', '287.jpg', '257.jpg']\n",
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zg_VpzSQ4q5y"
      },
      "outputs": [],
      "source": [
        "train_datagen =  ImageDataGenerator(\n",
        "        rescale=1.0/255.0,\n",
        "        rotation_range=40,\n",
        "        horizontal_flip=True,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest'\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzPUoXJa4sp9",
        "outputId": "4a7c14c2-2474-47e8-b1e4-38e188aa83f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 286 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(320, 320),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',shuffle=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-ucyPkFJFhX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(320, 320),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuH5cFfRlfKQ",
        "outputId": "bba23d3c-e53b-4bcd-dd87-2f6caae8e14f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "hBC2plzq43JC"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(320, 320, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(7, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "zBh2PIxR49IN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8080062f-fe32-4995-8a0f-5d576f07525a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "9/9 [==============================] - 47s 5s/step - loss: 16.4627 - accuracy: 0.0245 - val_loss: 2.5826 - val_accuracy: 0.2143\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 42s 5s/step - loss: 2.4396 - accuracy: 0.0769 - val_loss: 1.9098 - val_accuracy: 0.4429\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.9643 - accuracy: 0.2063 - val_loss: 1.8829 - val_accuracy: 0.3429\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 40s 5s/step - loss: 1.8985 - accuracy: 0.2483 - val_loss: 1.8317 - val_accuracy: 0.3714\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.8429 - accuracy: 0.1958 - val_loss: 1.7714 - val_accuracy: 0.2714\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.8546 - accuracy: 0.2343 - val_loss: 1.7045 - val_accuracy: 0.3857\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 40s 5s/step - loss: 1.7465 - accuracy: 0.3287 - val_loss: 1.5293 - val_accuracy: 0.5286\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 42s 5s/step - loss: 1.7221 - accuracy: 0.4476 - val_loss: 1.4564 - val_accuracy: 0.6000\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.5831 - accuracy: 0.4755 - val_loss: 1.2464 - val_accuracy: 0.6429\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.3926 - accuracy: 0.5455 - val_loss: 0.9845 - val_accuracy: 0.8429\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.2762 - accuracy: 0.5629 - val_loss: 1.0108 - val_accuracy: 0.7429\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 1.0979 - accuracy: 0.5979 - val_loss: 0.9297 - val_accuracy: 0.6857\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 40s 5s/step - loss: 0.9872 - accuracy: 0.6608 - val_loss: 0.6265 - val_accuracy: 0.8286\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 46s 5s/step - loss: 0.8762 - accuracy: 0.7448 - val_loss: 0.4154 - val_accuracy: 0.9000\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 41s 5s/step - loss: 0.6649 - accuracy: 0.8007 - val_loss: 0.3224 - val_accuracy: 0.9286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e5ae4510fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "model.compile(\n",
        "        optimizer='nadam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        epochs=15,\n",
        "        validation_data=validation_generator\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rwi_z_dc6DcQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "a58deec9-8656-4ecc-c7a5-904cc94cc67a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c425baf44267>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/extracted_data/mask_dataset/test_set/keras/117.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "test_image_path = \"/content/extracted_data/mask_dataset/test_set/keras/117.jpg\"\n",
        "test_image = cv2.imread(test_image_path)\n",
        "test_image = cv2.resize(test_image, (150, 150))\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "predictions = model.predict(test_image)\n",
        "print(predictions)\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Map the index to the class name\n",
        "class_labels = {v: k for k, v in train_generator.class_indices.items()}\n",
        "print(class_labels)\n",
        "predicted_class_name = class_labels[predicted_class_index[0]]\n",
        "\n",
        "# Print or use the predicted class name\n",
        "print(\"Predicted Class:\", predicted_class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlVYeHxF7EOX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}